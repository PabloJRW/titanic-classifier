{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "view-in-github"
   },
   "source": [
    "<a href=\"https://colab.research.google.com/github/PabloJRW/titanic-classifier/blob/main/notebooks/Preprocessing.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "id": "soBeWaKvQKGq"
   },
   "outputs": [],
   "source": [
    "import re\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.pipeline import Pipeline, make_pipeline\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.impute import SimpleImputer\n",
    "from sklearn.preprocessing import StandardScaler, OneHotEncoder, FunctionTransformer\n",
    "from joblib import dump"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def replace_values(series):\n",
    "    series[series >= 3] = 2\n",
    "    return series"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {
    "id": "Cdoj7O_mVGpj"
   },
   "outputs": [],
   "source": [
    "# Importing regular expression library\n",
    "import re\n",
    "\n",
    "def extract_title(series):\n",
    "    \"\"\"\n",
    "    Extract the social title from name.\n",
    "    E.g Mr, Mrs, Miss\n",
    "    \"\"\"\n",
    "    pattern = r\",\\s(.+?)\\s\"\n",
    "    df_col = pd.Series(series).fillna(\"\")\n",
    "    titles = df_col.apply(lambda x: re.search(pattern, x).group(1) if re.search(pattern, x) else \"\")\n",
    "    return np.array(titles).reshape(-1, 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {
    "id": "Uantj4la9Myk"
   },
   "outputs": [],
   "source": [
    "# numerical transformer pipeline (only 'fare')\n",
    "num_transformer = Pipeline(\n",
    "    steps=[\n",
    "        ('log_transform', FunctionTransformer(np.log1p)),\n",
    "        ('scaler', StandardScaler( ))\n",
    "    ]\n",
    ")\n",
    "\n",
    "# categorical transformer pipeline\n",
    "cat_transformer = Pipeline(\n",
    "    steps=[ \n",
    "        ('imputer', SimpleImputer(strategy='most_frequent')),\n",
    "        ('ohe', OneHotEncoder(handle_unknown='ignore'))\n",
    "    ]\n",
    ")\n",
    "\n",
    "mapper = Pipeline(\n",
    "    steps=[\n",
    "        ('mapper', FunctionTransformer(replace_values)),\n",
    "    ]\n",
    ")\n",
    "\n",
    "# \n",
    "socialt_transformer = Pipeline(\n",
    "    steps=[\n",
    "        ('extractor', FunctionTransformer(extract_title)),\n",
    "        ('ohe', OneHotEncoder(handle_unknown='ignore'))\n",
    "    ], \n",
    ")\n",
    "\n",
    "# Final pipeline\n",
    "preprocessing_pipeline = ColumnTransformer(\n",
    "    transformers=[\n",
    "        ('extract', socialt_transformer, 3),\n",
    "        #('num_transfomer', num_transformer, [9]),\n",
    "        #('cat_transformer', cat_transformer, [2, 4, 11]),\n",
    "        #('mapper_transformer', mapper, slice(6, 8))\n",
    "    ],remainder='drop', verbose=True\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {
    "id": "1fPX_DzejKVO"
   },
   "outputs": [],
   "source": [
    "# importing the training set\n",
    "url_train = \"https://raw.githubusercontent.com/PabloJRW/titanic-classifier/main/datasets/raw/train.csv\"\n",
    "df_train = pd.read_csv(url_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {
    "id": "AxpCrPOUi4WB"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ColumnTransformer] ....... (1 of 1) Processing extract, total=   0.0s\n"
     ]
    }
   ],
   "source": [
    "df_train_transformed = preprocessing_pipeline.fit_transform(df_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "-fWNYUEfqpUm",
    "outputId": "1bb09803-8474-4d95-f636-412855bbff41"
   },
   "outputs": [
    {
     "ename": "SyntaxError",
     "evalue": "unmatched ')' (403666846.py, line 1)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;36m  File \u001b[0;32m\"/tmp/ipykernel_5352/403666846.py\"\u001b[0;36m, line \u001b[0;32m1\u001b[0m\n\u001b[0;31m    pd.DataFrame(df_train_transformed).toarray())\u001b[0m\n\u001b[0m                                                ^\u001b[0m\n\u001b[0;31mSyntaxError\u001b[0m\u001b[0;31m:\u001b[0m unmatched ')'\n"
     ]
    }
   ],
   "source": [
    "pd.DataFrame(df_train_transformed).toarray()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "dUugRkKHlYkX",
    "outputId": "461dccd6-a2fc-4bd7-d2bb-0f98343af842"
   },
   "outputs": [],
   "source": [
    "# Saving the pipeline using joblib\n",
    "dump(preprocessing_pipeline, 'preprocessing_pipeline.joblib')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "U8uLsbiBmhkV"
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "colab": {
   "authorship_tag": "ABX9TyOk2+3THqnhiDq2v7uZOdlb",
   "include_colab_link": true,
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
